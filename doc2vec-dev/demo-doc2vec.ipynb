{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ee090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95959f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70062a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/dnk8n/src/clients/internship/internship/data/travel-wiki-extract-full-templates-processed.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e942c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dev\n",
    "# df = df.sample(50, random_state=42)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39204a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6fbffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe50159",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_text = train_df.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce683f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb26cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def friendly_tag_corpus(row):\n",
    "    doc_categories = row.categories.split('\\n')\n",
    "    doc_title = row.title\n",
    "    \n",
    "#     para_tags = []\n",
    "#     for para in row.words:\n",
    "#         sent_tags = []\n",
    "#         for sent in para:\n",
    "#             sent_tags.append([doc_title, *doc_categories])\n",
    "#         para_tags.append(sent_tags)\n",
    "#     return para_tags\n",
    "    return [doc_title, *doc_categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd327ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly = train_df[[\"title\", \"categories\"]].apply(friendly_tag_corpus, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f779986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tag_id_mapping(corpus_tags):\n",
    "    tags = list(set(tag for tags in corpus_tags for tag in tags))\n",
    "    return {tag: idx for idx, tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de724184",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id_mapping = build_tag_id_mapping(corpus_tags_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tag_mapping = {v: k for k,v in tag_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471781a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags = [[tag_id_mapping[tag] for tag in tags] for tags in corpus_tags_friendly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c671e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus2tokens(corpus_text, *args, **kwargs):\n",
    "    return [list(doc2tokens(doc)) for doc in nlp.pipe(corpus_text, *args, **kwargs)]\n",
    "\n",
    "\n",
    "def doc2tokens(doc):\n",
    "    for sent in doc.sents:\n",
    "        tokened_sent = sent2tokens(sent)\n",
    "        if tokened_sent:\n",
    "            yield tokened_sent\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token.text.lower() for token in sent if not (token.is_punct or token.is_space)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79308efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words = corpus2tokens(corpus_text, batch_size=15, n_process=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b637b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a74cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "[id_tag_mapping[tag] for tag in corpus_tags[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c761c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecba997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tagged_docs(corpus_words, corpus_tags):\n",
    "    for doc_words, doc_tags in zip(corpus_words, corpus_tags):\n",
    "        for sent_words in doc_words:\n",
    "            yield TaggedDocument(sent_words, doc_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(gen_tagged_docs(corpus_words, corpus_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57700dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Doc2Vec(vector_size=300, min_count=2, epochs=100)\n",
    "model = Doc2Vec(\n",
    "    vector_size=300,\n",
    "    epochs=200,\n",
    "    dm=0,\n",
    "    min_count=3,\n",
    "    negative=5,\n",
    "    hs=0,\n",
    "    sample=0,\n",
    "    workers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0846e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Word 'airport' appeared {model.wv.get_vecattr('airport', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67235e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43178ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv\n",
    "# wv.save('./doc2vec.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbab79ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(\"travel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = train_corpus[0].words\n",
    "print(doc)\n",
    "\n",
    "# Using words\n",
    "inferred_vector = model.infer_vector(doc)\n",
    "sims = model.dv.most_similar([inferred_vector], topn=10)\n",
    "for doc_id, factor in sims:\n",
    "    print(factor, id_tag_mapping[doc_id])\n",
    "\n",
    "print(\"************\")    \n",
    "\n",
    "# Using doc vector\n",
    "inferred_vector = model.dv[tag_id_mapping[\"Donakonda Airport\"]]\n",
    "sims = model.dv.most_similar([inferred_vector], topn=10)\n",
    "for doc_id, factor in sims:\n",
    "    print(factor, id_tag_mapping[doc_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b1842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[id_tag_mapping[tag] for tag in train_corpus[0].tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef99de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "\n",
    "train_corpus_copy = train_corpus.copy()\n",
    "random.shuffle(train_corpus_copy)\n",
    "sample_train_corpus = train_corpus_copy[:50]\n",
    "for sent_id in range(len(sample_train_corpus)):\n",
    "    inferred_vector = model.infer_vector(sample_train_corpus[sent_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(train_corpus))\n",
    "    most_similar_tag_indices = [\n",
    "        [docid for docid, sim in sims].index(tag)\n",
    "        for tag in sample_train_corpus[sent_id].tags\n",
    "\n",
    "    ]\n",
    "    rank = min(most_similar_tag_indices)\n",
    "    second_rank = max(most_similar_tag_indices) + 1\n",
    "    ranks.append(rank)\n",
    "    second_ranks.append(second_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "sum_0 = sum([v for k, v in counter.items() if k <= 0])\n",
    "sum_all_else = sum([v for k, v in counter.items() if k > 0])\n",
    "plt.bar([0,1], [sum_0, sum_all_else])\n",
    "print([sum_0, sum_all_else])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bec88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training example correctly matched (%): ', 100 * sum_0 / (sum_0 + sum_all_else))\n",
    "print('Training example incorrectly matched (%): ', 100 * sum_all_else / (sum_0 + sum_all_else))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d6e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_id = 42\n",
    "sentence = train_corpus[sent_id]\n",
    "article_tag_id = sentence.tags[0]\n",
    "inferred_vector = model.infer_vector(sentence.words)\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(train_corpus))\n",
    "print('Document ({} - {}): «{}»\\n'.format(id_tag_mapping[article_tag_id], train_df.loc[train_df.title == id_tag_mapping[article_tag_id]]['url'], ' '.join(sentence.words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "\n",
    "most_similar_tag_indices = [\n",
    "    [docid for docid, sim in sims].index(tag)\n",
    "    for tag in train_corpus[sent_id].tags\n",
    "\n",
    "]\n",
    "\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('THIRD-MOST', 2), ('JUST-OUTSIDE-TAGS', max(most_similar_tag_indices) + 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], id_tag_mapping[sims[index][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1882f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stream_corpus_to_dicst(corpus):\n",
    "#     for doc in corpus:\n",
    "#         yield {\n",
    "#             'words': doc.words,\n",
    "#             'tags': doc.tags\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659defc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import simplejson\n",
    "\n",
    "\n",
    "# def json_save(data, filename):\n",
    "#     with open(filename, 'w', encoding='utf-8') as f:\n",
    "#         simplejson.dump(data, f, separators=(',', ':'), iterable_as_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2789970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_save(stream_corpus_to_dicst(train_corpus), './doc2vec.corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_save(tag_id_mapping, './doc2vec.tag_id_mapping.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127777fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.stack(\n",
    "    tuple(\n",
    "        model.dv[tag]\n",
    "        for tag in set(\n",
    "            doc.tags[0]\n",
    "            for doc in train_corpus\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d98fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tags = set(doc.tags[0] for doc in train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ed1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "distortions = []\n",
    "testks = range(10,60, 10)\n",
    "for k in testks:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(x)\n",
    "    distortions.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(testks, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(x)\n",
    "clusters = kmeans.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc84df2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(x)\n",
    "x_pca = pca_result[:, 0]\n",
    "y_pca = pca_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_colors = np.array(['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000'])\n",
    "color = cluster_colors[clusters]\n",
    "#train_df['text'] = train_df.apply(lambda row: str(row.doc_id) + '-' + str(row.sent_id), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8300773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh.io\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "\n",
    "# from bokeh.charts import Donut, HeatMap, Histogram, Line, Scatter, show, output_notebook, output_file\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ce5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the data using bokeh\n",
    "\n",
    "# TOOLS = \"pan, xpan, ypan, xwheel_pan, ywheel_pan, \n",
    "#          wheel_zoom, xwheel_zoom, ywheel_zoom, zoom_in,\n",
    "#          xzoom_in, yzoom_in, zoom_out, xzoom_out, yzoom_out,\n",
    "#          click, tap, doubletap, crosshair, box_select,\n",
    "#          xbox_select, ybox_select, poly_select, lasso_select,\n",
    "#          box_zoom, xbox_zoom, ybox_zoom, save, undo, redo, reset,\n",
    "#          help, box_edit, line_edit, point_draw, poly_draw,\n",
    "#          poly_edit, freehand_draw or hover\"\n",
    "\n",
    "source = ColumnDataSource(dict(x=x_pca, y=y_pca, colur=color))\n",
    "tools = \"pan,wheel_zoom,box_zoom,reset,hover,save\"\n",
    "\n",
    "plot = figure(plot_width=800, plot_height=450, tools=tools)\n",
    "\n",
    "#draw circles\n",
    "plot.circle(y='y', x='x', source=source, size=15, fill_color='color')\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d5b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
