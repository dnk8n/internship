{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15745d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e959d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('./full.csv')\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1043a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.iloc[395].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482fd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv('./train.csv')\n",
    "# df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('./test.csv')\n",
    "# df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810be093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dev\n",
    "# df_train = df_train.sample(50, random_state=42)\n",
    "# df_test = df_test.sample(50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce534041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_text_train = df_train.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ed7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_text_full = df_full.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08498ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(corpus_text_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus_text_full[-1][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def friendly_tag_corpus_train(row):\n",
    "#     doc_categories = row.categories.split('\\n')\n",
    "#     doc_title = row.title\n",
    "#     return [doc_title, *doc_categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29269f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def friendly_tag_corpus_full(row):\n",
    "    if str(row.category) == \"nan\":\n",
    "        doc_category = None\n",
    "    else:\n",
    "        doc_category = row.category\n",
    "    if not doc_category:\n",
    "        doc_category = None\n",
    "    doc_title = row.title\n",
    "    return [\n",
    "        f'title:{doc_title}',\n",
    "        *[f'category:{d}' for d in [doc_category] if d is not None],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_friendly_train = df_train[[\"title\", \"categories\"]].apply(friendly_tag_corpus_train, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly_full = df_full[[\"title\", \"category\"]].apply(friendly_tag_corpus_full, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_friendly_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d33fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly_full[-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(corpus_tags_friendly_train), len(corpus_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_tags_friendly_full), len(corpus_text_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a922b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tag_id_mapping(corpus_tags):\n",
    "    tags = list(set(tag for tags in corpus_tags for tag in tags))\n",
    "    return {tag: idx for idx, tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_id_mapping = build_tag_id_mapping(corpus_tags_friendly_train)\n",
    "# id_tag_mapping = {v: k for k, v in tag_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id_mapping = build_tag_id_mapping(corpus_tags_friendly_full)\n",
    "id_tag_mapping = {v: k for k, v in tag_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_train = [[tag_id_mapping[tag] for tag in tags] for tags in corpus_tags_friendly_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a70701",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_full = [[tag_id_mapping[tag] for tag in tags] for tags in corpus_tags_friendly_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfafe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(corpus_tags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e42eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_tags_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.utils import simple_preprocess\n",
    "\n",
    "# def corpus2tokens(raw_corpus):\n",
    "#     return [simple_preprocess(doc) for doc in tqdm_notebook(raw_corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.lang.en import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "# nlp.add_pipe(\"merge_noun_chunks\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "single_quote_unicode = ord(\"'\")\n",
    "translation_table_text = str.maketrans(\n",
    "    {\n",
    "        '`': single_quote_unicode,\n",
    "        '‘': single_quote_unicode,\n",
    "        '’': single_quote_unicode,\n",
    "        '“': single_quote_unicode,\n",
    "        '”': single_quote_unicode,\n",
    "        '-': None,\n",
    "    }\n",
    ")\n",
    "translation_table_token = str.maketrans(\n",
    "    {\n",
    "        \"'\": None,\n",
    "        '\"': None,\n",
    "        '.': None\n",
    "    }\n",
    ")\n",
    "\n",
    "def substitute_token(token):\n",
    "    token_lowered = token.lower()\n",
    "    if 'http' in token_lowered:\n",
    "        print(f'WARNING: {token_lowered} is getting converted to URL')\n",
    "        return 'URL'\n",
    "    elif '@' in token_lowered:\n",
    "        print(f'WARNING: {token_lowered} is getting converted to USERMENTION')\n",
    "        return 'USERMENTION'\n",
    "    elif '&amp;' in token_lowered:\n",
    "        print(f'WARNING: {token_lowered} is getting converted to \"and\"')\n",
    "        return 'and'\n",
    "    elif \"ain't\" in token_lowered:\n",
    "        print(f'WARNING: {token_lowered} is getting converted to \"am not\"')\n",
    "        return 'am not'\n",
    "    elif '\\x89û_' in token_lowered:\n",
    "        print(f'WARNING: {token_lowered} is getting converted to \"{token_lowered[:-3]}\"')\n",
    "        return f'{token_lowered[:-3]} ...'\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "def corpus2tokens(corpus_text, *args, **kwargs):\n",
    "    corpus_text = [' '.join([substitute_token(token) for token in text.translate(translation_table_token).split()]) for text in corpus_text]\n",
    "    return [doc2tokens(doc) for doc in nlp.pipe(tqdm.notebook.tqdm(corpus_text), *args, **kwargs)]\n",
    "\n",
    "def doc2tokens(doc):\n",
    "    tokens = [token for token in doc if not (token.is_punct or token.is_space)]\n",
    "    return process_tokens(tokens, doc.ents)\n",
    "\n",
    "def show_ents(ents):\n",
    "    for ent in ents:\n",
    "        print(ent.text+' - ' +str(ent.start_char) +' - '+ str(ent.end_char) +' - '+ent.label_+ ' - '+str(spacy.explain(ent.label_)))\n",
    "\n",
    "def process_tokens(tokens, ents, rm_stopwords=False):\n",
    "    ent_vals_to_skip = ['#', '\\\\\\\\\\\\']\n",
    "    ent_labels_to_sub = [\n",
    "        \"DATE\", # Absolute or relative dates or periods\n",
    "        \"CARDINAL\", # Numerals that do not fall under another type\n",
    "        \"PERCENT\", # Percentage, including \"%\"\n",
    "        \"TIME\", # Times smaller than a day\n",
    "        \"MONEY\", # Monetary values, including unit\n",
    "        \"ORDINAL\", # \"first\", \"second\", etc.\n",
    "        \"QUANTITY\", # Measurements, as of weight or distance\n",
    "    ]\n",
    "    tokens_processed = []\n",
    "    stringed_ents = [ent.text.lower() for ent in ents if ent.text not in ent_vals_to_skip]\n",
    "    ent_tokens = []\n",
    "    for token in tokens:\n",
    "        stringed_token = token.text.lower()\n",
    "        if stringed_token in stringed_ents:\n",
    "            ent_tokens.append(stringed_token)\n",
    "            ent_label = ents[stringed_ents.index(stringed_token)].label_\n",
    "            if ent_label in ent_labels_to_sub:\n",
    "                tokens_processed.append(ent_label)\n",
    "                continue\n",
    "            stringed_token = ent_label + \"|\" + stringed_token.translate(translation_table_token)\n",
    "        if rm_stopwords:\n",
    "            if stringed_token not in STOP_WORDS:\n",
    "                tokens_processed.append(stringed_token)\n",
    "        else:\n",
    "            tokens_processed.append(stringed_token)\n",
    "    len_ent_tokens = len(set(ent_tokens))\n",
    "    len_stringed_ents = len(set(stringed_ents))\n",
    "    if len_ent_tokens != len_stringed_ents:\n",
    "        print(f'WARNING: Somehow the number of unique tokens which are ents ({len_ent_tokens}) does not match the total number of unique ents ({len_stringed_ents})')\n",
    "        diff = list(set(stringed_ents) - set(ent_tokens))\n",
    "        if not diff:\n",
    "            diff = list(set(ent_tokens) - set(stringed_ents))\n",
    "            print(diff, \"exist in tokens but not in ents\")\n",
    "        print(diff, \"exist in ents but not in tokens\")\n",
    "        print(\"tokens: \", \"\\n\", tokens, \"\\n\\n\")\n",
    "        print(\"ents: \", \"\\n\", ents, \"\\n\\n\")\n",
    "    return tokens_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# corpus_words_train = corpus2tokens(corpus_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed9acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_words_full = corpus2tokens(corpus_text_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words_full[-1][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdaeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain('GPE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_full[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72289358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [id_tag_mapping[tag] for tag in corpus_tags_train[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe8f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "[id_tag_mapping[tag] for tag in corpus_tags_full[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad62fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id_tag_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tagged_docs(corpus_words, corpus_tags):\n",
    "    return [TaggedDocument(doc_words, doc_tags) for doc_words, doc_tags in zip(corpus_words, corpus_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e278fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_train = gen_tagged_docs(corpus_words_train, corpus_tags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a0eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full = gen_tagged_docs(corpus_words_full, corpus_tags_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://groups.google.com/g/gensim/c/6JmSsx4iIv0\n",
    "# projects with larger vocabularies tend to lean more towards negative-sampling than hierarchical-softmax\n",
    "# VERY NB - https://stackoverflow.com/a/37502976/1782641\n",
    "# https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "model = Doc2Vec(\n",
    "    vector_size=1000,\n",
    "    epochs=200,\n",
    "    min_count=10,\n",
    "    window=10,\n",
    "    hs=0,\n",
    "    negative=20,\n",
    "    sample=1e-3,\n",
    "    workers=3  # 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b35816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.build_vocab(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5960c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.build_vocab(corpus_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Word 'airport' appeared {model.wv.get_vecattr('airport', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeba1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Word 'airport' appeared {model.wv.get_vecattr('airport', 'count')} times in the full corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.train(corpus_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(corpus_full, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b29631",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv\n",
    "wv.save('./doc2vec.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_to_dicts(corpus):\n",
    "    for doc in corpus:\n",
    "        yield {\n",
    "            'words': doc.words,\n",
    "            'tags': doc.tags\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c674b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson\n",
    "\n",
    "\n",
    "def json_save(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        simplejson.dump(data, f, separators=(',', ':'), iterable_as_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33822b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_save(corpus_to_dicts(corpus_train), './doc2vec.corpus.train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save(corpus_to_dicts(corpus_full), './doc2vec.corpus.full.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa82abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save(tag_id_mapping, './doc2vec.tag_id_mapping.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7baf91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('./test.csv')\n",
    "# df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_text_test = df_test.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(corpus_text_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c732ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def friendly_tag_corpus_test(row):\n",
    "#     return row.categories.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_friendly_test = df_test[[\"categories\"]].apply(friendly_tag_corpus_test, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253517c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_friendly_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(corpus_tags_friendly_test), len(corpus_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb51127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weed out tags that were not seen in training\n",
    "# corpus_tags_test = [[tag_id_mapping.get(tag) for tag in tags] for tags in corpus_tags_friendly_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_friendly_test[89], corpus_tags_test[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f43f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# corpus_words_test = corpus2tokens(corpus_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_words_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_tags_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [id_tag_mapping[tag] for tag in corpus_tags_test[5] if tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f23c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_test = gen_tagged_docs(corpus_words_test, corpus_tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34670147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_save(corpus_to_dicts(corpus_test), './doc2vec.corpus.test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
