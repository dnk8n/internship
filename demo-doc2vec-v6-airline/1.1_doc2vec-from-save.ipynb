{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7386013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson\n",
    "\n",
    "def json_load(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return simplejson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "def gen_tagged_docs(corpus):\n",
    "    return [TaggedDocument(doc[\"words\"], doc[\"tags\"]) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a896ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_similar_article_and_categories(corpus, doc_id=0, topn=10, by_article_tokens=True, by_article_tag=False):\n",
    "    doc = corpus[doc_id].words\n",
    "    print(' '.join(doc)[:200])\n",
    "\n",
    "    if by_article_tokens:\n",
    "        # Using words\n",
    "        print(\"************\")    \n",
    "        print(\"Get simlarity based on tokens:\")\n",
    "        print()    \n",
    "        inferred_vector = model.infer_vector(doc)\n",
    "        sims = model.dv.most_similar([inferred_vector], topn=topn)\n",
    "        for idx, factor in sims:\n",
    "            print(factor, id_tag_mapping[idx])  \n",
    "\n",
    "    if by_article_tag:\n",
    "        # Using doc vector\n",
    "        print(\"************\")    \n",
    "        print(\"Get simlarity based on article tag:\")\n",
    "        print()    \n",
    "        inferred_vector = model.dv[corpus[doc_id].tags[0]]\n",
    "        sims = model.dv.most_similar([inferred_vector], topn=topn)\n",
    "        for idx, factor in sims:\n",
    "            print(factor, id_tag_mapping[idx])\n",
    "    \n",
    "    print(\"************\")\n",
    "    print(\"Actual known tags:\")\n",
    "    print()\n",
    "    print([id_tag_mapping.get(tag) for tag in corpus[doc_id].tags if tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def rank_by_inferredvector(corpus, sent_ids):\n",
    "    ranks = []\n",
    "    for sent_id in sent_ids:\n",
    "        inferred_vector = model.infer_vector(corpus[sent_id].words)\n",
    "        sims = model.dv.most_similar([inferred_vector], topn=len(id_tag_mapping))\n",
    "        most_similar_tag_indices = [\n",
    "            [docid for docid, _ in sims].index(tag)\n",
    "            for tag in corpus[sent_id].tags if tag\n",
    "        ]\n",
    "        if most_similar_tag_indices:\n",
    "            rank = min(most_similar_tag_indices)\n",
    "            print(f'{sent_id}: Ranked {rank} ({id_tag_mapping[sims[rank][0]]}) out of {len(sims)}')\n",
    "            ranks.append(rank)\n",
    "    return ranks\n",
    "\n",
    "            \n",
    "def rank_by_random(corpus, sent_ids):\n",
    "    return [random.randint(0, len(id_tag_mapping)) for _ in sent_ids]\n",
    "\n",
    "\n",
    "def plot_matches(corpus, rank_func=rank_by_inferredvector, take_sample=True, sample_size=50, sample_seed=42, topn_perc=0.1):\n",
    "    if take_sample:\n",
    "        random.seed(sample_seed)\n",
    "        sent_ids = random.sample(range(0, len(corpus)), sample_size)\n",
    "    else:\n",
    "        sent_ids = list(range(len(corpus)))\n",
    "    ranks = rank_func(corpus, sent_ids)\n",
    "    counter = collections.Counter(ranks)\n",
    "    group_0 = []\n",
    "    group_1 = []\n",
    "    group_2 = []\n",
    "    for k, v in counter.items():\n",
    "        if k == 0:\n",
    "            group_0.append(v)\n",
    "        elif k < len(id_tag_mapping) / (100 / topn_perc):\n",
    "            group_1.append(v)\n",
    "        else:\n",
    "            group_2.append(v)\n",
    "        sum_0 = sum(group_0)\n",
    "        sum_1_acceptable = sum(group_1)\n",
    "        sum_all_else = sum(group_2)\n",
    "    plt.bar([0,1,2], [sum_0, sum_1_acceptable, sum_all_else])\n",
    "    print([sum_0, sum_1_acceptable, sum_all_else])\n",
    "    print('Test example correctly matched (%): ', 100 * sum_0 / sum([sum_0, sum_1_acceptable, sum_all_else]))\n",
    "    print(f'Test example matched in top {topn_perc}% (%): ', 100 * sum_1_acceptable / sum([sum_0, sum_1_acceptable, sum_all_else]))\n",
    "    print('Test example badly matched (%): ', 100 * sum_all_else / sum([sum_0, sum_1_acceptable, sum_all_else]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97991b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec.load('./doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load('./doc2vec.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_train_raw = json_load('./doc2vec.corpus.train.json')\n",
    "# corpus_test_raw = json_load('./doc2vec.corpus.test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb00edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full = json_load('./doc2vec.corpus.full.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_types = set(word.split('|')[0] for doc in corpus_full for word in doc['words'] if '|' in word)\n",
    "entity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(word_count_dict, label):\n",
    "    wordcloud = WordCloud(width = 1000, height = 500).generate_from_frequencies(word_count_dict)\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.show()\n",
    "    plt.savefig(f'{label}.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_stopwords = [\n",
    "    \"DATE\", # Absolute or relative dates or periods\n",
    "    \"CARDINAL\", # Numerals that do not fall under another type\n",
    "    \"PERCENT\", # Percentage, including \"%\"\n",
    "    \"TIME\", # Times smaller than a day\n",
    "    \"MONEY\", # Monetary values, including unit\n",
    "    \"ORDINAL\", # \"first\", \"second\", etc.\n",
    "    \"QUANTITY\", # Measurements, as of weight or distance\n",
    "    \"said\"\n",
    "]\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from spacy.lang.en import STOP_WORDS\n",
    "\n",
    "for entity_type in entity_types:\n",
    "    word_count_dict=Counter(list(word.split('|')[-1] for doc in corpus_full for word in doc['words'] if entity_type in word))\n",
    "    save_image(word_count_dict, entity_type)\n",
    "word_count_dict=Counter(list(word.split('|')[-1] for doc in corpus_full for word in doc['words'] if word.split('|')[-1] not in STOP_WORDS and word.split('|')[-1] not in extra_stopwords))\n",
    "save_image(word_count_dict, 'ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'hello|there'.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa0a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dev\n",
    "# corpus_train_raw = corpus_train_raw[:50]\n",
    "# corpus_test_raw = corpus_test_raw[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_train = gen_tagged_docs(corpus_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f51cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus_full = gen_tagged_docs(corpus_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ebbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id_mapping = json_load('./doc2vec.tag_id_mapping.json')\n",
    "id_tag_mapping = {v: k for k, v in tag_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f2027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plot_matches(corpus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff3c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_matches(tagged_corpus_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_similar_article_and_categories(corpus_train, doc_id=425, by_article_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4afa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus_full[425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30409be",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similar_article_and_categories(tagged_corpus_full, doc_id=425, by_article_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e78c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse (unseen) test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_test = gen_tagged_docs(corpus_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plot_matches(corpus_test, take_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a893bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_similar_article_and_categories(corpus_test, doc_id=13317)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b982c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df_test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.iloc[5914]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8227cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plot_matches(corpus_test, sample_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee387659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plot_matches(corpus_test, sample_size=1000, topn_perc=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
