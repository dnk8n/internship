{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefe6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4602581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cca27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(input_data_path / \"input.xlsx\")\n",
    "# FOR DEV... SHOULD BE ABLE TO REMOVE THE LINE BELOW\n",
    "df = df.sample(10000, random_state=42)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99834167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_save(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "def json_load(filename):\n",
    "    with open(filename) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d344815",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = df['texts'].values.tolist()\n",
    "json_save(text_corpus, './text_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996dde9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_corpus_tokenizer(text_corpus):\n",
    "    for text in text_corpus:\n",
    "        # print(text[:79])\n",
    "        yield custom_text_tokenizer(text)\n",
    "\n",
    "def custom_text_tokenizer(text):\n",
    "    tokens = []\n",
    "    for token in nlp(text):\n",
    "        # print(\"token.text: \", token.text)\n",
    "        # print(\"token.is_alpha: \", token.is_alpha)\n",
    "        # print(\"token.is_stop: \", token.is_stop)\n",
    "        # print(\"token.is_punct\", token.is_punct)\n",
    "        if (\n",
    "            token.is_alpha\n",
    "            and not (\n",
    "                token.is_stop\n",
    "                or token.is_punct\n",
    "                or len(token.text) <= 1\n",
    "            )\n",
    "        ):\n",
    "            # print(\"token.lemma_.lower(): \", token.lemma_.lower())\n",
    "            tokens.append(token.lemma_.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f30ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokened corpus is used twice, once to compile dictionary and again to compile vectorized_corpus... so can't use a generator here (Can potentially stream to disk, then load it in each of the two cases to save on RAM)\n",
    "tokened_corpus = list(custom_corpus_tokenizer(text_corpus))\n",
    "json_save(tokened_corpus, './tokened_corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146be8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokened_corpus)\n",
    "dictionary.save('./tokened_corpus.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a016d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary)\n",
    "# dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9743dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_tokens(once_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebb09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.compactify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df80787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedCorpus:\n",
    "    def __iter__(self):\n",
    "        for tokened_doc in tokened_corpus:\n",
    "            yield dictionary.doc2bow(tokened_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd105a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_corpus = list(VectorizedCorpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dcb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora.MmCorpus.serialize('./vectorized_corpus.mm', vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c5985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that taking n-grams into account is not necessary for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01467148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorized_corpus = list(tfidf[vectorized_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Potentially ommit tokens with scores below a determined threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5135f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(vectorized_corpus, id2word=dictionary, num_topics=5000)\n",
    "lsi.save('./lsi.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_vectorized_corpus = list(lsi[vectorized_corpus])\n",
    "corpora.MmCorpus.serialize('./lsi_vectorized_corpus.mm', lsi_vectorized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cosine similarity for now, but consider Jensen-Shannon\n",
    "\n",
    "# Also compare lsi/lda/tfidf\n",
    "\n",
    "#https://www.kaggle.com/ktattan/lda-and-document-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03414cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d87e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_similarity_index = similarities.MatrixSimilarity(lsi[lsi_vectorized_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d8bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_similarity_index.save('./lsi_similarity.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top3_most_similar(example_doc):\n",
    "    vec_bow = dictionary.doc2bow(custom_text_tokenizer(example_doc))\n",
    "    vec_lsi = lsi[vec_bow]\n",
    "    sims = sorted(enumerate(lsi_similarity_index[vec_lsi]), key=lambda item: -item[1])\n",
    "    for doc_position, doc_score in sims[:3]:\n",
    "        print(doc_score, text_corpus[doc_position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d90d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example doc to compare against lsi similarity index\n",
    "example_doc_1 = \"The company’s cloud services business combined with a surge in Prime subscriptions to increase revenue 31% year on year  This article is more than 3 years old  This article is more than 3 years old  Amazon Web Services, the company’s cloud service division, has long provided the infrastructure for vast retail websites and plucky startups alike, from Netflix and Airbnb to Nasa and the Royal Opera House, but is now seen as the company’s biggest driver of growth.  AWS combined with enthusiastic take-up of its premium Prime service to generate better than expected revenue for the second quarter of the year.  Total revenue reached $30.4bn, up 31% from the same period in 2015 and higher than analysts’ expectations of $29.55bn, while AWS surged 58.2% to $2.89bn – slightly higher than the estimate of $2.83bn predicted by market research firm FactSet StreetAccount.  Prime offers free shipping on products from the site as well as exclusive film and TV content, advertising-free content and unlimited photo storage. A dedicated promotional Prime Day on 12 July is also expected to help drive sales of between $31.0bn and $33.5bn for the current quarter.  The company’s net sales rose 31.1% to $30.40bn in the second quarter ending 30 June. Sales in North America, its biggest market, jumped 28.1% to $17.67bn.    Why so much coverage of Amazon Prime Day. The incentives, of course Read more  Amazon also saw its net profit reach a record high of $857m, continuing a relatively new strategy of recording profit rather than reinvesting in its business – though it last quarter committed to investing $5bn into its business in India.  It’s been a busy few months for Amazon around the world, and particularly in India, said the CEO, Jeff Bezos, in a statement.  We launched a new AWS region, introduced Prime with unlimited free shipping, and announced that Prime Video is coming soon, offering Prime members in India exclusive access to Amazon Original Series and Movies – including original content featuring top Indian creators and talent.  The world’s biggest online retailer’s shares were up 2% in after-hours trading on Thursday.\"\n",
    "print_top3_most_similar(example_doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_doc_2 = \" The Amazon makes up almost a third of all tropical rainforests left on Earth, and is a vital carbon sink Three hundred million people worldwide live in forests and 1.6 billion depend on them for their livelihoods.Forests provide habitat for a vast array of plants and animals, many of which are still undiscovered.These ecosystems are so much more than a collection of trees, they are home to 80 per cent of the world’s terrestrial biodiversity.The Amazon Rainforest makes up nearly a third of all the tropical rainforests left on Earth and it plays a vital role in sustaining life on the planet to help stabilise the climate.Yet, this vast, tropical wilderness and its inhabitants are losing the fight for survival. The Amazon’s 2020 fire season is imminent and set to be at least as bad as last year.This follows continued deforestation and illegal invaders who take advantage of reduced law enforcement to snatch indigenous and protected lands, destroying this precious and irreplaceable natural habitat\"\n",
    "print_top3_most_similar(example_doc_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
