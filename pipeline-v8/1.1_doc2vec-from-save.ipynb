{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba18297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim import matutils\n",
    "\n",
    "def similarity_cosine(vec1, vec2):\n",
    "    cosine_similarity = np.dot(matutils.unitvec(vec1), matutils.unitvec(vec2))\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7386013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson\n",
    "\n",
    "def json_load(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return simplejson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "def gen_tagged_docs(corpus):\n",
    "    return [TaggedDocument(doc[\"tokens\"], doc[\"tags\"]) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a896ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_similar_article_and_categories(corpus, doc_id=0, topn=10, by_article_tokens=True, by_article_tag=False):\n",
    "    doc = corpus[doc_id].words\n",
    "    print(' '.join(doc)[:200])\n",
    "\n",
    "    if by_article_tokens:\n",
    "        # Using words\n",
    "        print(\"************\")    \n",
    "        print(\"Get simlarity based on tokens:\")\n",
    "        print()    \n",
    "        inferred_vector = model.infer_vector(doc)\n",
    "        sims = model.dv.most_similar([inferred_vector], topn=topn)\n",
    "        for idx, factor in sims:\n",
    "            print(factor, idx)  \n",
    "\n",
    "    if by_article_tag:\n",
    "        # Using doc vector\n",
    "        print(\"************\")    \n",
    "        print(\"Get simlarity based on article tag:\")\n",
    "        print()    \n",
    "        inferred_vector = model.dv[corpus[doc_id].tags[0]]\n",
    "        sims = model.dv.most_similar([inferred_vector], topn=topn)\n",
    "        for idx, factor in sims:\n",
    "            print(factor, idx)\n",
    "    \n",
    "    print(\"************\")\n",
    "    print(\"Actual known tags:\")\n",
    "    print()\n",
    "    print([tag for tag in corpus[doc_id].tags if tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def rank_by_inferredvector(corpus, sent_ids):\n",
    "    ranks = []\n",
    "    for sent_id in sent_ids:\n",
    "        inferred_vector = model.infer_vector(corpus[sent_id].words)\n",
    "        sims = model.dv.most_similar([inferred_vector], topn=len(corpus))\n",
    "        most_similar_tag_indices = [\n",
    "            [docid for docid, _ in sims].index(tag)\n",
    "            for tag in corpus[sent_id].tags if tag\n",
    "        ]\n",
    "        if most_similar_tag_indices:\n",
    "            rank = min(most_similar_tag_indices)\n",
    "            print(f'{sent_id}: Ranked {rank} ({sims[rank][0]}) out of {len(sims)}')\n",
    "            ranks.append(rank)\n",
    "    return ranks\n",
    "\n",
    "            \n",
    "def rank_by_random(corpus, sent_ids):\n",
    "    return [random.randint(0, len(corpus)) for _ in sent_ids]\n",
    "\n",
    "\n",
    "def plot_matches(corpus, rank_func=rank_by_inferredvector, take_sample=True, sample_size=50, sample_seed=42, topn_perc=0.1):\n",
    "    if take_sample:\n",
    "        random.seed(sample_seed)\n",
    "        sent_ids = random.sample(range(0, len(corpus)), sample_size)\n",
    "    else:\n",
    "        sent_ids = list(range(len(corpus)))\n",
    "    ranks = rank_func(corpus, sent_ids)\n",
    "    counter = collections.Counter(ranks)\n",
    "    group_0 = []\n",
    "    group_1 = []\n",
    "    group_2 = []\n",
    "    for k, v in counter.items():\n",
    "        if k == 0:\n",
    "            group_0.append(v)\n",
    "        elif k < len(corpus) / (100 / topn_perc):\n",
    "            group_1.append(v)\n",
    "        else:\n",
    "            group_2.append(v)\n",
    "        sum_0 = sum(group_0)\n",
    "        sum_1_acceptable = sum(group_1)\n",
    "        sum_all_else = sum(group_2)\n",
    "    plt.bar([0,1,2], [sum_0, sum_1_acceptable, sum_all_else])\n",
    "    print([sum_0, sum_1_acceptable, sum_all_else])\n",
    "    print('Test example correctly matched (%): ', 100 * sum_0 / sum([sum_0, sum_1_acceptable, sum_all_else]))\n",
    "    print(f'Test example matched in top {topn_perc}% (%): ', 100 * sum_1_acceptable / sum([sum_0, sum_1_acceptable, sum_all_else]))\n",
    "    print('Test example badly matched (%): ', 100 * sum_all_else / sum([sum_0, sum_1_acceptable, sum_all_else]))\n",
    "    \n",
    "\n",
    "def determine_matches_strict(corpus, sent_ids):\n",
    "    sum_matches = 0\n",
    "    sum_nomatches = 0\n",
    "    for sent_id in sent_ids:\n",
    "        inferred_vector = model.infer_vector(corpus[sent_id].words)\n",
    "        sims = model.dv.most_similar([inferred_vector], topn=len(corpus))\n",
    "        actual_tags = set(t for t, _ in sims[:len(corpus[sent_id].tags)])\n",
    "        expected_tags = set(corpus[sent_id].tags)\n",
    "        if actual_tags == expected_tags:\n",
    "            sum_matches += 1\n",
    "        else:\n",
    "            print('actual_tags:', [t for t in actual_tags])\n",
    "            print('expected_tags:', [t for t in expected_tags])\n",
    "            sum_nomatches += 1\n",
    "    return sum_matches, sum_nomatches\n",
    "    \n",
    "    \n",
    "def plot_matches_strict(corpus, take_sample=True, sample_size=50, sample_seed=42):\n",
    "    if take_sample:\n",
    "        random.seed(sample_seed)\n",
    "        sent_ids = random.sample(range(0, len(corpus)), sample_size)\n",
    "    else:\n",
    "        sent_ids = list(range(len(corpus)))\n",
    "    sum_match, sum_nomatch = determine_matches_strict(corpus, sent_ids)\n",
    "    plt.bar([0,1], [sum_match, sum_nomatch])\n",
    "    print([sum_match, sum_nomatch])\n",
    "    print('Test example correctly matched (%): ', 100 * sum_match / sum([sum_match, sum_nomatch]))\n",
    "    print('Test example badly matched (%): ', 100 * sum_nomatch / sum([sum_match, sum_nomatch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a112927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def cluster_plot(X, n, cluster_ids, **kwargs):\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    scaler = StandardScaler(**kwargs)\n",
    "    scaler.fit(X) \n",
    "    X_scaled = scaler.transform(X)\n",
    "\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(X_scaled) \n",
    "    X_pca = pca.transform(X_scaled) \n",
    "\n",
    "    Xax = X_pca[:,0]\n",
    "    Yax = X_pca[:,1]\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure()\n",
    "    if n == 3:\n",
    "        Zax = X_pca[:,2]\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(Xax, Yax, Zax, c=cluster_ids, s=20)\n",
    "        ax.view_init(30, 185)\n",
    "    elif n == 2:\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(Xax, Yax, c=cluster_ids, s=20)\n",
    "    else:\n",
    "        print('Invalid')\n",
    "        return\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def kmeans_plot(vecs, k_range):\n",
    "    x = np.stack(vecs)\n",
    "\n",
    "    distortions = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        kmeans.fit(x)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(k_range, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('The Elbow Method showing the optimal k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050bb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_ids(n, vecs):\n",
    "    x = np.stack(vecs)\n",
    "    kmeans = KMeans(n_clusters=n)\n",
    "    kmeans.fit(x)\n",
    "    cluster_ids = kmeans.predict(x)\n",
    "    return cluster_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602c488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def get_pairwise_simularities(vectors):\n",
    "    sims = []\n",
    "    for a, b in itertools.combinations(list(range(490)), 2):\n",
    "        sims.append((a, b, similarity_cosine(vectors[a], vectors[b]),))\n",
    "    a, b, sim = zip(*sims)\n",
    "    for i in sims:\n",
    "        if i[2] > 0.8:\n",
    "            print(i)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97991b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec.load('./doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load('./doc2vec.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb00edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full = json_load('./doc2vec.corpus.full.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f51cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_corpus_full = gen_tagged_docs(corpus_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# plot_matches_strict(tagged_corpus_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4afa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similar_article_and_categories(tagged_corpus_full, doc_id=319, by_article_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30409be",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similar_article_and_categories(tagged_corpus_full, doc_id=29, by_article_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vecs_unfiltered = [model.dv[v] for v in range(len(corpus_full))]\n",
    "kmeans_plot(doc_vecs_unfiltered, range(1,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc166b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids_unfiltered = get_cluster_ids(2, doc_vecs_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_plot(doc_vecs_unfiltered, 2, cluster_ids_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e13073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "cluster_plot(doc_vecs_unfiltered, 3, cluster_ids_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_unfiltered = get_pairwise_simularities(model.dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bda549",
   "metadata": {},
   "outputs": [],
   "source": [
    "informing_ents = [\n",
    "    'PERSON',\n",
    "    'NORP',\n",
    "    'ORG',\n",
    "    'EVENT',\n",
    "    'LANGUAGE',\n",
    "    'LOC',\n",
    "    'GPE',\n",
    "    'FAC',\n",
    "    'LAW',\n",
    "    'PRODUCT',\n",
    "    'MISC'\n",
    "]\n",
    "\n",
    "corpus_filtered_by_ents = [[token for token, ent_type in doc if ent_type in informing_ents] for doc in json_load('./doc2vec.corpus_token_objects.json')]\n",
    "tagged_corpus_filtered_by_ents = [TaggedDocument(doc, [doc_id]) for doc_id, doc in enumerate(corpus_filtered_by_ents)]\n",
    "doc_vecs_filtered_by_ents = [\n",
    "    model.infer_vector(doc) for doc in corpus_filtered_by_ents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "kmeans_plot(doc_vecs_filtered_by_ents, range(1,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a65bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_filtered_by_ents = get_cluster_ids(3, doc_vecs_filtered_by_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55752fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_plot(doc_vecs_filtered_by_ents, 2, clusters_filtered_by_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ea68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "cluster_plot(doc_vecs_filtered_by_ents, 3, clusters_filtered_by_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_filtered_by_ents = get_pairwise_simularities(doc_vecs_filtered_by_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full[414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2950e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full[431]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similar_article_and_categories(tagged_corpus_filtered_by_ents, doc_id=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10294b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_similar_article_and_categories(tagged_corpus_filtered_by_ents, doc_id=319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered_by_ents[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered_by_ents[319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered_by_ents[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42245e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647956e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full[319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa2137",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_full[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "informing_ents_reduced = [\n",
    "    'PERSON',\n",
    "#     'NORP',\n",
    "    'ORG',\n",
    "#     'EVENT',\n",
    "#     'LANGUAGE',\n",
    "    'LOC',\n",
    "    'GPE',\n",
    "    'FAC',\n",
    "#     'LAW',\n",
    "#     'PRODUCT',\n",
    "#     'MISC'\n",
    "]\n",
    "\n",
    "corpus_filtered_by_ents_reduced = [[token for token, ent_type in doc if ent_type in informing_ents_reduced] for doc in json_load('./doc2vec.corpus_token_objects.json')]\n",
    "tagged_corpus_filtered_by_ents_reduced = [TaggedDocument(doc, [doc_id]) for doc_id, doc in enumerate(corpus_filtered_by_ents_reduced)]\n",
    "doc_vecs_filtered_by_ents_reduced = [\n",
    "    model.infer_vector(doc) for doc in corpus_filtered_by_ents_reduced\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef149fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "kmeans_plot(doc_vecs_filtered_by_ents_reduced, range(1,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_filtered_by_ents_reduced = get_cluster_ids(3, doc_vecs_filtered_by_ents_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_plot(doc_vecs_filtered_by_ents_reduced, 2, clusters_filtered_by_ents_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_plot(doc_vecs_filtered_by_ents_reduced, 3, clusters_filtered_by_ents_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017dea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_filtered_by_ents_reduced_list = list(clusters_filtered_by_ents_reduced)\n",
    "len(clusters_filtered_by_ents_reduced_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b509f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0_terms = set()\n",
    "cluster1_terms = set()\n",
    "cluster2_terms = set()\n",
    "for idx, cluster in enumerate(clusters_filtered_by_ents_reduced_list):\n",
    "    ents = corpus_filtered_by_ents_reduced[idx]\n",
    "    if cluster == 0:\n",
    "        relevant_set = cluster0_terms\n",
    "    elif cluster == 1:\n",
    "        relevant_set = cluster1_terms\n",
    "    elif cluster == 2:\n",
    "        relevant_set = cluster2_terms\n",
    "    for ent in ents:\n",
    "        relevant_set.add(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cluster0_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fce7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cluster1_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cluster2_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fabe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_filtered_by_ents_for_tfidf_reduced = [' '.join((token.replace(' ', '_') for token in doc)) for doc in corpus_filtered_by_ents_reduced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a483f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get vecs with bag of words method. Build vocab from ents\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus_filtered_by_ents_for_tfidf_reduced)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab28a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "kmeans_plot(X.todense(), range(1,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 2\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(X)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67485dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_plot(X.todense(), 2, clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90def3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
