{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15745d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ba5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ubuntu/internship/data/travel-wiki-extract-full-templates-processed.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"text\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810be093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dev\n",
    "# df = df.sample(50, random_state=42)\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce534041",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_text = train_df.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08498ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus_text[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def friendly_tag_corpus(row):\n",
    "    doc_categories = row.categories.split('\\n')\n",
    "    doc_title = row.title\n",
    "    return [doc_title, *doc_categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly = train_df[[\"title\", \"categories\"]].apply(friendly_tag_corpus, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_tags_friendly), len(corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a922b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tag_id_mapping(corpus_tags):\n",
    "    tags = list(set(tag for tags in corpus_tags for tag in tags))\n",
    "    return {tag: idx for idx, tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id_mapping = build_tag_id_mapping(corpus_tags_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c316f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tag_mapping = {v: k for k, v in tag_id_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags = [[tag_id_mapping[tag] for tag in tags] for tags in corpus_tags_friendly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfafe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22e0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b95b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus2tokens(corpus_text, *args, **kwargs):\n",
    "    return [list(doc2tokens(doc)) for doc in nlp.pipe(tqdm_notebook(corpus_text), *args, **kwargs)]\n",
    "\n",
    "def doc2tokens(doc):\n",
    "    return [token.text.lower() for token in doc if not (token.is_punct or token.is_space)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_words = corpus2tokens(corpus_text, batch_size=40, n_process=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec81d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72289358",
   "metadata": {},
   "outputs": [],
   "source": [
    "[id_tag_mapping[tag] for tag in corpus_tags[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad62fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id_tag_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tagged_docs(corpus_words, corpus_tags):\n",
    "    for doc_words, doc_tags in zip(corpus_words, corpus_tags):\n",
    "        yield TaggedDocument(doc_words, doc_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e278fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(gen_tagged_docs(corpus_words, corpus_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://groups.google.com/g/gensim/c/6JmSsx4iIv0\n",
    "# projects with larger vocabularies tend to lean more towards negative-sampling than hierarchical-softmax\n",
    "# VERY NB - https://stackoverflow.com/a/37502976/1782641\n",
    "# https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "model = Doc2Vec(\n",
    "    vector_size=1000,\n",
    "    epochs=200,\n",
    "    min_count=10,\n",
    "    window=10,\n",
    "    hs=0,\n",
    "    negative=20,\n",
    "    sample=1e-3,\n",
    "    workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b35816",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeba1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Word 'airport' appeared {model.wv.get_vecattr('airport', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b29631",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99cc15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv\n",
    "wv.save('./doc2vec.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee98c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[id_tag_mapping[tag] for tag in train_corpus[0].tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf063b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "\n",
    "train_corpus_copy = train_corpus.copy()\n",
    "random.shuffle(train_corpus_copy)\n",
    "sample_train_corpus = train_corpus_copy[:50]\n",
    "for sent_id in range(len(sample_train_corpus)):\n",
    "    inferred_vector = model.infer_vector(sample_train_corpus[sent_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(id_tag_mapping))\n",
    "    most_similar_tag_indices = [\n",
    "        [docid for docid, sim in sims].index(tag)\n",
    "        for tag in sample_train_corpus[sent_id].tags\n",
    "    ]\n",
    "    rank = min(most_similar_tag_indices)\n",
    "    second_rank = max(most_similar_tag_indices) + 1\n",
    "    ranks.append(rank)\n",
    "    second_ranks.append(second_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78084f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "sum_0 = sum([v for k, v in counter.items() if k <= 0])\n",
    "sum_all_else = sum([v for k, v in counter.items() if k > 0])\n",
    "plt.bar([0,1], [sum_0, sum_all_else])\n",
    "print([sum_0, sum_all_else])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training example correctly matched (%): ', 100 * sum_0 / (sum_0 + sum_all_else))\n",
    "print('Training example incorrectly matched (%): ', 100 * sum_all_else / (sum_0 + sum_all_else))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7576f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_corpus_to_dicst(corpus):\n",
    "    for doc in corpus:\n",
    "        yield {\n",
    "            'words': doc.words,\n",
    "            'tags': doc.tags\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c674b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson\n",
    "\n",
    "\n",
    "def json_save(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        simplejson.dump(data, f, separators=(',', ':'), iterable_as_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33822b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save(stream_corpus_to_dicst(train_corpus), './doc2vec.corpus.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa82abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save(tag_id_mapping, './doc2vec.tag_id_mapping.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7baf91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./test.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d4068",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_text_test = df_test.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus_text_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c732ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def friendly_tag_test_corpus(row):\n",
    "    return row.categories.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e6540",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly_test = df_test[[\"categories\"]].apply(friendly_tag_test_corpus, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253517c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus_tags_friendly_test), len(corpus_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb51127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weed out tags that were not seen in training\n",
    "corpus_tags_test = [[tag_id_mapping.get(tag) for tag in tags] for tags in corpus_tags_friendly_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_friendly_test[89], corpus_tags_test[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f43f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "corpus_words_test = corpus2tokens(corpus_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_words_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tags_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[id_tag_mapping[tag] for tag in corpus_tags_test[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f23c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test = list(gen_tagged_docs(corpus_words_test, corpus_tags_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34670147",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save(stream_corpus_to_dicst(corpus_test), './doc2vec.corpus.test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
